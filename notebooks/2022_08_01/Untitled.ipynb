{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "089ad36f-8f27-4a72-9f37-0ad4805903dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58032608-c9a6-46c2-8642-631788dea3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import time\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import river\n",
    "\n",
    "from ic import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89867d10-7043-40a5-b27f-bc57a91a2023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_to_dataframe(evaluation_step):\n",
    "    return pd.DataFrame({\n",
    "        'accuracy': evaluation_step['Accuracy'].get(),\n",
    "        'recall': evaluation_step['Recall'].get(),\n",
    "        'precision': evaluation_step['Precision'].get(),\n",
    "        'f1': evaluation_step['F1'].get(),\n",
    "    }, index=[evaluation_step['Step']])\n",
    "\n",
    "\n",
    "def evaluate_prequential_delayed(\n",
    "    model, stream, delay=500, eval_step=500\n",
    "):\n",
    "    metrics = river.metrics.base.Metrics(\n",
    "        metrics=[\n",
    "            river.metrics.Accuracy(),  \n",
    "            river.metrics.Recall(), \n",
    "            river.metrics.Precision(),\n",
    "            river.metrics.F1()\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    step_iterator = river.evaluate.iter_progressive_val_score(\n",
    "        model=model, \n",
    "        dataset=stream, \n",
    "        metric=metrics, \n",
    "        step=eval_step,\n",
    "        delay=delay\n",
    "    )\n",
    "    \n",
    "    metrics_df = pd.DataFrame()\n",
    "    \n",
    "    for step in step_iterator:\n",
    "        metrics_df = pd.concat([metrics_df, step_to_dataframe(step)])\n",
    "    \n",
    "    return metrics_df\n",
    "\n",
    "\n",
    "def metrics_to_dataframe(step, metrics):\n",
    "    return pd.DataFrame(dict(\n",
    "        zip(\n",
    "            ['accuracy', 'recall', 'precision', 'f1'],\n",
    "            [ [ m.get() ] for m in metrics ]\n",
    "        )\n",
    "    ), index=[step])\n",
    "\n",
    "\n",
    "def evaluate_prequential_delayed_1(\n",
    "    model, stream, delay=500, eval_step=500\n",
    "):\n",
    "    delay_queue = deque()\n",
    "    \n",
    "    metrics = river.metrics.base.Metrics(\n",
    "        metrics=[\n",
    "            river.metrics.Accuracy(),  \n",
    "            river.metrics.Recall(), \n",
    "            river.metrics.Precision(),\n",
    "            river.metrics.F1()\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    metrics_df = pd.DataFrame()\n",
    "    \n",
    "    for step, (X, y) in enumerate(stream):\n",
    "        y_pred = model.predict_one(X)\n",
    "        metrics.update(y_true=y, y_pred=y_pred)\n",
    "        \n",
    "        delay_queue.append((X, y))\n",
    "        while len(delay_queue) > delay:\n",
    "            X, y = delay_queue.popleft()\n",
    "            model.learn_one(X, y)\n",
    "    \n",
    "        if (step+1)%eval_step == 0:\n",
    "            metrics_df = pd.concat([metrics_df, metrics_to_dataframe(step+1, metrics)])\n",
    "    \n",
    "    return metrics_df\n",
    "\n",
    "\n",
    "def warm_up_and_evaluate(model, stream, n_warm_up_rows=1000):\n",
    "    for _ in range(n_warm_up_rows):\n",
    "        X, y = next(stream)\n",
    "        model.learn_one(X, y)\n",
    "    \n",
    "    return evaluate_prequential_delayed(model, stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e78779d-3577-4542-a8ef-a6296a687e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_dataset(path, target):\n",
    "    chunks = pd.read_csv(path, chunksize=1000)\n",
    "    for chunk in chunks:\n",
    "        for _, row in chunk.iterrows():\n",
    "            yield (row[row.index != target], row[target])\n",
    "            \n",
    "            \n",
    "def process_evaluation(model, label, file_path):\n",
    "    out_path = f'../../data/2022_08_01/metrics/{util.basename(file_path)}.{label}.metrics.csv'        \n",
    "    stream = yield_dataset(file_path, target='Label')\n",
    "\n",
    "    start_time = time.time()\n",
    "    h_m = time.strftime('%H:%M')\n",
    "    print(f'Starting {label} - {h_m}')\n",
    "\n",
    "    metrics = warm_up_and_evaluate(model, stream)\n",
    "    metrics.to_csv(out_path, index_label='step')\n",
    "\n",
    "    print(f'Took {int((time.time()-start_time)/60)} mins\\n')\n",
    "\n",
    "    model_out_path = f'../../trained_models/2022_08_01/{label}_{util.basename(file_path)}.joblib'\n",
    "    joblib.dump(model, model_out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4047875-a9ea-44b8-81ba-dee93cfd7fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting HoeffdingTree - 22:58\n",
      "Took 5 mins\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_evaluation(\n",
    "    river.tree.HoeffdingTreeClassifier(),\n",
    "    'HoeffdingTree',\n",
    "    '../../data/2022_08_01/processed/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.processed.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f58e7267-8a71-4334-b737-272a38db8298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Bagging - 23:03\n",
      "Took 46 mins\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_evaluation(\n",
    "    river.ensemble.BaggingClassifier(\n",
    "        model=river.tree.HoeffdingTreeClassifier()\n",
    "    ),\n",
    "    'Bagging',\n",
    "    '../../data/2022_08_01/processed/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.processed.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50ccd375-c644-4eed-a8f0-8fc2b605c86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ADWINBagging - 23:50\n",
      "Took 49 mins\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_evaluation(\n",
    "    river.ensemble.ADWINBaggingClassifier(\n",
    "        model=river.tree.HoeffdingTreeClassifier()\n",
    "    ),\n",
    "    'ADWINBagging',\n",
    "    '../../data/2022_08_01/processed/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.processed.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735c421f-2a25-4dbc-bef1-a0969ac30ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting KNN - 00:39\n"
     ]
    }
   ],
   "source": [
    "process_evaluation(\n",
    "    river.neighbors.KNNClassifier(),\n",
    "    'KNN',\n",
    "    '../../data/2022_08_01/processed/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.processed.csv'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
